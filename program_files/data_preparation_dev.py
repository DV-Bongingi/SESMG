import osfrom sklearn.cluster import KMeansimport pandas as pdimport numpy as npdef extract_single_periods(data_set, column_name, period):    """        Extracts individual periods of a certain column of a weather data        set as lists. Caution: weather data set must be available in        hourly resolution!        Parameters        ----------        data_set: weather data set to be extractet        column_name: column name of which the extraction should be applied        period: indicates what kind of periods shall be extractet. Possible                arguments: "days", "weeks".        Returns        -------        cluster_vectors: list, containing a list/vector for every single day    """    if period == "days":        timesteps = 24    elif period == "weeks":        timesteps = 168    elif period == "hours":        timesteps = 1    # extract data_set of cluster_criterion    cluster_df = data_set[column_name]    # extract single periods as lists and add them to a list    cluster_vectors = []    for i in range(0, int(len(cluster_df) / timesteps)):        cluster_vector = []        for j in range(timesteps):            cluster_vector.append(cluster_df[i * timesteps + j])        cluster_vectors.append(cluster_vector)    # returns the list with extracted day data sets    return cluster_vectorsdef calculate_k_means_clusters(cluster_number, weather_data, cluster_criterion,                               period):    """        Applies the k-means algorithm to a list of day-weather-vectors.        Caution: weather data set must be available in hourly resolution!        Parameters        ----------        cluster_number: Number of k-mean-clusters        weather_data: weather_data, the clusters should be applied to        cluster_criterion: weather_parameter/column name which should be                           applied as cluster criterion        Returns        -------        model.labels_: Chronological list, which days of the weather data                       set belongs to which cluster    """    cluster_vectors = extract_single_periods(data_set=weather_data,                                             column_name=cluster_criterion,                                             period=period)    kmeans = KMeans(n_clusters=cluster_number)    model = kmeans.fit(cluster_vectors)    return model.labels_def calculate_cluster_means(data_set, cluster_number, cluster_labels, period):    """        Determines weather averages of the individual clusters for a weather        dataset, based on predetermined cluster allocation. Caution: weather        data set must be available in hourly resolution!        Parameters        ----------        data_set: data_set, the clusters should be applied to        cluster_number: Number of clusters        cluster_labels: Chronological list, which days of the weather                        data set belongs to which cluster        Returns        -------        prep_data_set: pandas dataframe containing the prepared weather                       data set    """    column_names = [data_set.columns[i] for i in                    range(1, len(data_set.columns))]    # Define pandas Dataframe for final data_setset    prep_data_set = pd.DataFrame()    # Loop for every column of the weather data set    for i in range(len(column_names) - 1):        # Extract individual weather data set for the current weather data column        data_set_column = extract_single_periods(data_set=data_set, column_name=column_names[i], period=period)        # Define empty list used later        reference_data_set = []        # Loop for every cluster        for j in range(0, cluster_number):  # FÃ¼r jedes k-Means Cluster            # Define empty list used later            cluster_dataset = []            # Loop for every day of the weather data set            for k in range(len(data_set_column)):                # if the day belongs to the current cluster, it will be appended to 'cluster_dataset'                if cluster_labels[k] == j:                    cluster_dataset.append(data_set_column[k])            # Calculates the mean for ever hour of the current cluster            cluster_dataset_array = np.array(cluster_dataset)            # Appends the calculated mean values to the 'reference_data_set' list            reference_data_set = reference_data_set + cluster_dataset_array.mean(axis=0).tolist()        # Appends the calculated reference days for the curent weather data collumn to the final weather data set        prep_data_set[column_names[i]] = reference_data_set    return prep_data_setdef k_means_parameter_adaption(nodes_data, clusters, cluster_labels, period):    '''    To be able to work with the adapted weather data set some parameters from    nodes_data must be changed.    Parameters    ----------    nodes_data: system parameters    k_mean_parameters: k-means-clustering parameters (dictionary)    Returns    -------    '''    # Addapting variable costs    if period == 'days':        variable_cost_factor = int(nodes_data['energysystem']['periods']) / int(24*clusters)        print('VARIABLE COST FACTOR')        print(variable_cost_factor)    elif period == 'weeks':        variable_cost_factor = int(nodes_data['energysystem']['periods']) / int(7*24 * clusters)        print('VARIABLE COST FACTOR')        print(variable_cost_factor)    elif period == 'hours':        variable_cost_factor = int(nodes_data['energysystem']['periods']) / int(clusters)        print('VARIABLE COST FACTOR')        print(variable_cost_factor)    # Adapting Costs    nodes_data['sources']['variable costs'] = nodes_data['sources']['variable costs']*variable_cost_factor    nodes_data['buses']['excess costs'] = nodes_data['buses']['excess costs'] * variable_cost_factor    nodes_data['buses']['shortage costs'] = nodes_data['buses']['shortage costs'] * variable_cost_factor    nodes_data['transformers']['variable input costs'] = nodes_data['transformers']['variable input costs'] * variable_cost_factor    nodes_data['transformers']['variable output costs'] = nodes_data['transformers']['variable output costs'] * variable_cost_factor    nodes_data['transformers']['variable output costs 2'] = nodes_data['transformers']['variable output costs 2'] * variable_cost_factor    nodes_data['storages']['variable input costs'] = nodes_data['storages']['variable input costs'] * variable_cost_factor    nodes_data['storages']['variable output costs'] = nodes_data['storages']['variable output costs'] * variable_cost_factor    nodes_data['links']['variable output costs'] = nodes_data['links']['variable output costs'] * variable_cost_factor    # Adapting Constraint Costs    nodes_data['sources']['variable constraint costs'] = nodes_data['sources']['variable constraint costs']*variable_cost_factor    nodes_data['buses']['variable excess constraint costs'] = nodes_data['buses']['variable excess constraint costs'] * variable_cost_factor    nodes_data['buses']['variable shortage constraint costs'] = nodes_data['buses']['variable shortage constraint costs'] * variable_cost_factor    nodes_data['transformers']['variable input constraint costs'] = nodes_data['transformers']['variable input constraint costs'] * variable_cost_factor    nodes_data['transformers']['variable output constraint costs'] = nodes_data['transformers']['variable output constraint costs'] * variable_cost_factor    nodes_data['transformers']['variable output constraint costs 2'] = nodes_data['transformers']['variable output constraint costs 2'] * variable_cost_factor    nodes_data['storages']['variable input constraint costs'] = nodes_data['storages']['variable input constraint costs'] * variable_cost_factor    nodes_data['storages']['variable output constraint costs'] = nodes_data['storages']['variable output constraint costs'] * variable_cost_factor    nodes_data['links']['variable constraint costs'] = nodes_data['links']['variable constraint costs'] * variable_cost_factor    # Adapting Demands    nodes_data['sinks']['annual demand'] = nodes_data['sinks']['annual demand'] / variable_cost_factor    # Addapting timesystem parameters    if period == 'days':        nodes_data['energysystem']['end date'] = nodes_data['energysystem']['start date'] + pd.Timedelta(str(clusters*24-1)+' hours')        nodes_data['energysystem']['periods'] = int(24*clusters)    elif period == 'weeks':        nodes_data['energysystem']['end date'] = nodes_data['energysystem']['start date'] + pd.Timedelta(str(clusters*7*24-1)+' hours')        nodes_data['energysystem']['periods'] = int(7*24*clusters)    elif period == 'hours':        nodes_data['energysystem']['end date'] = nodes_data['energysystem']['start date'] + pd.Timedelta(str(clusters-1)+' hours')        nodes_data['energysystem']['periods'] = int(clusters)def k_means_timeseries_adaption(nodes_data, clusters, cluster_labels, period):    prep_timeseries = calculate_cluster_means(data_set = nodes_data['timeseries'],                                              cluster_number = clusters,                                              cluster_labels = cluster_labels, period=period)    # Rename columns of the new timeseries-dataset    if period == 'days':        prep_timeseries['timestamp'] = nodes_data['timeseries']['timestamp'][:int(len(nodes_data['timeseries']) / clusters)]    elif period == 'weeks':        prep_timeseries['timestamp'] = nodes_data['timeseries']['timestamp'][:int(len(nodes_data['timeseries']) / (clusters*7))]    # prep_timeseries.set_index('timestamp', inplace=True)    nodes_data['timeseries'] = prep_timeseriesdef k_means_algorithm(clusters, criterion, nodes_data, period):    if criterion == 'el_demand_sum' or criterion == 'heat_demand_sum':        weather_data = nodes_data['timeseries']    else:        weather_data = nodes_data['weather data']    # Calculate k-mean clusters, based on the cluster_criterion    cluster_labels = calculate_k_means_clusters(cluster_number= clusters,                                                weather_data= weather_data,                                                cluster_criterion=criterion,                                                period=period)    weather_data = nodes_data['weather data']    # Apply the Clusters to the entire weather_dataset    prep_weather_data = calculate_cluster_means(data_set = weather_data,                                                cluster_number = clusters,                                                cluster_labels = cluster_labels,                                                period=period)    # Rename columns of the new weather_dataset    prep_weather_data['timestamp'] = weather_data['timestamp'][:len(prep_weather_data)]    prep_weather_data.set_index('timestamp', inplace=True)    # Replaces the weather data set in nodes_data by the new one    nodes_data['weather data'] = prep_weather_data    # Adapts Other Parameters (despite weatherdata) of the energy system    k_means_parameter_adaption(nodes_data, clusters, cluster_labels, period)    k_means_timeseries_adaption(nodes_data, clusters, cluster_labels, period)def timeseries_averaging(clusters, nodes_data, period):    weather_data = nodes_data['weather data']    if period == 'days':        periods = int(len(weather_data) / 24)    elif period == 'weeks':        periods = int(len(weather_data) /(24*7))    cluster_labels = []    for i in range(clusters):        for j in range(periods // clusters):            cluster_labels.append(i)    if periods % clusters >= 0:        for k in range(periods % clusters):            cluster_labels.append(clusters - 1)    cluster_labels = np.array(cluster_labels)    # Apply the Clusters to the entire weather_dataset    prep_weather_data = calculate_cluster_means(data_set=weather_data,                                                cluster_number=clusters,                                                cluster_labels=cluster_labels,                                                period=period)    # Rename columns of the new weather_dataset    prep_weather_data['timestamp'] = weather_data['timestamp'][:len(prep_weather_data)]    prep_weather_data.set_index('timestamp', inplace=True)    # Replaces the weather data set in nodes_data by the new one    nodes_data['weather data'] = prep_weather_data    # Adapts Other Parameters (despite weatherdata) of the energy system    k_means_parameter_adaption(nodes_data, clusters, cluster_labels, period)    k_means_timeseries_adaption(nodes_data, clusters, cluster_labels, period)def data_set_slicing(n_days, data_set, period):    # slicing, where EVERY N-TH DAY IS ~SELECTED~    column_names = [data_set.columns[i] for i in                    range(1, len(data_set.columns))]    prep_data_set = pd.DataFrame()    # Loop for every column of the weather data set    for i in range(len(column_names)):        # Extract individual weather data set for the current weather data column        data_set_column = extract_single_periods(data_set=data_set, column_name=column_names[i], period=period)        # If the data set is not divisible by the corresponding number of periods, the data set is shortened accordingly        if len(data_set_column)%n_days > 0:            data_set_column = data_set_column[0:-(len(data_set_column)%n_days)]        sliced_column = data_set_column[0::n_days]        reference_data_set = []        for j in range(len(sliced_column)):            reference_data_set = reference_data_set + sliced_column[j]        # Appends the calculated reference days for the current weather data column to the final weather data set        prep_data_set[column_names[i]] = reference_data_set    return prep_data_setdef data_set_slicing2(n_days, data_set, period):    # slicing, where EVERY N-TH DAY IS ~DELETED~    column_names = [data_set.columns[i] for i in                    range(1, len(data_set.columns))]    prep_data_set = pd.DataFrame()    # Loop for every column of the weather data set    for i in range(len(column_names)):        # Extract individual weather data set for the current weather data column        data_set_column = extract_single_periods(data_set=data_set, column_name=column_names[i], period=period)        # Falls der Datensatz nicht durch die entsprechende Periodenanzahl teilbar ist, wird        # der Datensatz entsprechend gekÃ¼rzt        if len(data_set_column)%n_days > 0:            data_set_column = data_set_column[0:-(len(data_set_column)%n_days)]        sliced_column = data_set_column        del sliced_column[n_days-1::n_days]#data_set_column[0::n_days]        reference_data_set = []        for j in range(len(sliced_column)):            reference_data_set = reference_data_set + sliced_column[j]        # Appends the calculated reference days for the curent weather data collumn to the final weather data set        prep_data_set[column_names[i]] = reference_data_set    return prep_data_setdef timeseries_slicing(n_days, nodes_data, period):    weather_data=nodes_data['weather data']    data_set = nodes_data['weather data']    prep_weather_data = data_set_slicing(n_days, data_set=data_set, period=period)    # Rename columns of the new weather_dataset    prep_weather_data['timestamp'] = weather_data['timestamp'][:len(prep_weather_data)]#:int(len(prep_weather_data))]    prep_weather_data.set_index('timestamp', inplace=True)    # Replaces the weather data set in nodes_data by the new one    nodes_data['weather data'] = prep_weather_data    # Adapts Other Parameters (despite weatherdata) of the energy system    if period == 'days':        adaption_clusters = len(prep_weather_data)/24    elif period == 'weeks':        adaption_clusters = len(prep_weather_data)/(24*7)    elif period == 'hours':        adaption_clusters = len(prep_weather_data)    k_means_parameter_adaption(nodes_data=nodes_data,                               clusters=adaption_clusters, # TODO: relativen wert einfÃ¼gen!                               cluster_labels=0,                               period=period)    prep_timeseries = data_set_slicing(n_days, data_set=nodes_data['timeseries'], period=period)    prep_timeseries['timestamp'] = nodes_data['timeseries']['timestamp'][:len(prep_weather_data)]    # prep_timeseries.set_index('timestamp', inplace=True)    nodes_data['timeseries'] = prep_timeseriesdef timeseries_slicing2(n_days, nodes_data, period):    weather_data=nodes_data['weather data']    data_set = nodes_data['weather data']    prep_weather_data = data_set_slicing2(n_days, data_set=data_set, period=period)    # Rename columns of the new weather_dataset    prep_weather_data['timestamp'] = weather_data['timestamp'][:len(prep_weather_data)]#:int(len(prep_weather_data))]    prep_weather_data.set_index('timestamp', inplace=True)    # Replaces the weather data set in nodes_data by the new one    nodes_data['weather data'] = prep_weather_data    if period == 'days':        adaption_clusters = len(prep_weather_data)/24    elif period == 'weeks':        adaption_clusters = len(prep_weather_data)/(24*7)    elif period == 'hours':        adaption_clusters = len(prep_weather_data)    # Adapts Other Parameters (despite weatherdata) of the energy system    print('LEN PREP WEATHER DATA')    print(len(prep_weather_data))    k_means_parameter_adaption(nodes_data=nodes_data,                               clusters=adaption_clusters,                               cluster_labels=0,                               period=period)    prep_timeseries = data_set_slicing2(n_days, data_set=nodes_data['timeseries'], period=period)    prep_timeseries['timestamp'] = nodes_data['timeseries']['timestamp'][:len(prep_weather_data)]    nodes_data['timeseries'] = prep_timeseriesdef timeseries_downsampling(nodes_data, n_timesteps):    nodes_data['timeseries'] = nodes_data['timeseries'].iloc[::n_timesteps,:]    nodes_data['weather data'] = nodes_data['weather data'].iloc[::n_timesteps,:]    nodes_data['weather data'].set_index('timestamp', inplace=True)    nodes_data['energysystem']['temporal resolution'] = str(n_timesteps)+nodes_data['energysystem']['temporal resolution']    nodes_data['energysystem']['periods'] = int(nodes_data['energysystem']['periods']/n_timesteps)def timeseries_downsampling2(nodes_data, n_timesteps):    nodes_data['timeseries'] = nodes_data['timeseries'].iloc[::n_timesteps]#,:]    # del nodes_data['timeseries'].iloc[n_timesteps - 1::n_timesteps]    nodes_data['weather data'] = nodes_data['weather data'].iloc[::n_timesteps]#,:]    # del nodes_data['weather data'][n_timesteps - 1::n_timesteps]    nodes_data['weather data'].set_index('timestamp', inplace=True)    prep_timeseries['timestamp'] = nodes_data['timeseries']['timestamp'][:len(prep_weather_data)]def hierarchical_selection(nodes_data, scheme, period, seasons, scheme_path):    """ Algorithm for the hierarchical selection of representative time periods    of a weather data set. In this embodiment, the following representative    periods are selected for every season (winter, spring, summer, fall) are    selected:    - Week containing the coldest temperature of the season    - Week with the lowest average sun duration    - Week containing the warmest temperature of the season    - Week with the highest average sun duration    :param nodes_data: SESMG-nodes data, containing weather data, energy system                       parameters and timeseries    :return: nodes_data: modified SESMG-nodes data, containing weather data,                         energy system parameters and timeseries    """    def extract_data_slices(data_set, timesteps):        ''' extracts slices of a defined length of a dataset. E.g. slices of weeks        (168 timesteps) of a weather data set may be extracted.'''        list_of_data_slices = []        for i in range(len(data_set) // timesteps):            period_data_set = data_set[i * timesteps:(i + 1) * timesteps]            list_of_data_slices.append(period_data_set)        return list_of_data_slices    def identify_timeseries_minimum(data_set, column_name):        """ returns the minimum value of a certain column of a given        data_set        """        return min(data_set[column_name])    def identify_minimum_week(data_set, criterion, value):        ''' Returns the week with a minimum value of a certain column. Either        the week with the absolute minimum value, or the week with the average        minimum value can be selected.        :param data_set: Dataset        :param criterion: column, which is the criterion of the selection        :param value: 'extreme' for absolute minimum value, 'average' for                       average minimum value selection        :return: minimum_week: Dataset of the selected minimum week        '''        absolute_minimum = 99999999        for i in range(len(data_set)):            # weekly_minimum = identify_timeseries_minimum(data_set=data_set[i],            #                                              column_name=criterion)            if value == "extreme":                weekly_minimum = identify_timeseries_minimum(                    data_set=data_set[i],                    column_name=criterion)            elif value == "average":                weekly_minimum = identify_timeseries_average(                    data_set=data_set[i],                    column_name=criterion)            if weekly_minimum < absolute_minimum:                absolute_minimum = weekly_minimum                minimum_week = data_set[i]        return minimum_week    def identify_timeseries_maximum(data_set, column_name):        """ returns the maximum value of a certain column of a given        data_set        """        return max(data_set[column_name])    def identify_timeseries_average(data_set, column_name):        """ returns the average value of a certain column of a given        data_set.        """        list = data_set[column_name]        return 0 if len(list) == 0 else sum(list) / len(list)    def identify_maximum_week(data_set, criterion, value):        """ Returns the week with a maximum value of a certain column. Either        the week with the absolute maximum value, or the week with the average        maximum value can be selected.        :param data_set: Dataset        :param criterion: column, which is the criterion of the selection        :param value: 'extreme' for absolute maximum value, 'average' for                       average maximum value selection        :return: minimum_week: Dataset of the selected maximum week        """        absolute_maximum = -99999999        for i in range(len(data_set)):            if value == "extreme":                weekly_maximum = identify_timeseries_maximum(                    data_set=data_set[i],                    column_name=criterion)            elif value == "average":                weekly_maximum = identify_timeseries_average(                    data_set=data_set[i],                    column_name=criterion)            if weekly_maximum > absolute_maximum:                absolute_maximum = weekly_maximum                maximum_week = data_set[i]        return maximum_week    def identify_average_week(data_set, criterion):        """ Returns the week with the most average series of a certain column.        :param data_set: Dataset        :param criterion: column, which is the criterion of the selection        :return: minimum_week: Dataset of the selected maximum week        """        # Creates a list with the average value of every week        list_of_averages = []        for i in range(len(data_set)):            weekly_average = identify_timeseries_average(data_set=data_set[i],                                                         column_name=criterion)            list_of_averages.append(weekly_average)        # Calculates the average of the entire dataset        absolute_average = 0 if len(list_of_averages) == 0 else sum(list_of_averages) / len(list_of_averages)        # Checks which average is closest to the absolute average        deviation = 999999999999        for i in range(len(data_set)):            if abs(list_of_averages[i] - absolute_average) <= deviation:                deviation = abs(list_of_averages[i] - absolute_average)                average_data = data_set[i]        return average_data    def create_period_weather_data(weather_data, period):        # Splits the given weather data_set in nodes_data into weekly weather data        # sets        if period == 'weeks':            period_length = 24*7        elif period == 'days':            period_length = 24                        period_data_slices = extract_data_slices(            data_set=nodes_data['weather data'], timesteps=period_length)        return period_data_slices    def create_period_season_weather_data(period_data_slices, period, seasons):        '''Splits a given weather data (one year) set into weekly weather data        slices and sorts them into lists of every season of the year (each        season is defined by a length of 13 weeks) and returns a list,        containing a list of weater data weeks for every season.        :param weather_data: weather data of one year, to be modified        :param timesteps:        :return: list, containing list of weekly weather data slices of every                 season.        '''        if period == 'weeks':            period_length = 24 * 7        elif period == 'days':            period_length = 24        season_length = len(period_data_slices) // seasons        # Splits the given weather data_set in nodes_data into weekly weather data sets        period_data_slices = extract_data_slices(data_set=nodes_data['weather data'], timesteps=period_length)        # Sorts the weekly weather data sets into seasons. One season is defined by 13 consequtive weeks here        season_data = []        for i in range(seasons):            periods_data = period_data_slices[season_length*(i):season_length*(i+1)]            season_data.append(periods_data)        return season_data    def select_heuristic_periods(heuristic_periods,                                 period_data_slices,                                 season_data,                                 period,                                 seasons):        '''Selects and returns representative values of time series according         to a given heuristic scheme.                :param heuristic_periods:        :param period_data_slices:        :param season_data:        :param period:        :param seasons:        :return:        '''        prep_weather_data = pd.DataFrame()        if seasons == 4:            for representative in heuristic_periods:                if representative[0] == 'winter':                    data_set = season_data[0]                elif representative[0] == 'spring':                    data_set = season_data[1]                elif representative[0] == 'summer':                    data_set = season_data[2]                elif representative[0] == 'fall':                    data_set = season_data[3]                elif representative[0] == 'year':                    data_set = period_data_slices                if representative[1] == 'lowest':                    selected_week = identify_minimum_week(data_set=data_set,                                                        criterion=representative[2],                                                        value=representative[3])                elif representative[1] == 'highest':                    selected_week = identify_maximum_week(                        data_set=data_set,                        criterion=representative[2],                        value=representative[3])                elif representative[1] == 'average':                    selected_week = identify_average_week(                        data_set=data_set,                        criterion=representative[2])                prep_weather_data = prep_weather_data.append(selected_week)        if seasons == 12:            for representative in heuristic_periods:                if representative[0] == 'year':                    data_set = period_data_slices                else:                    data_set = season_data[int(representative[0])-1]                if representative[1] == 'lowest':                    selected_week = identify_minimum_week(data_set=data_set,                                                          criterion=                                                          representative[2],                                                          value=representative[                                                              3])                elif representative[1] == 'highest':                    selected_week = identify_maximum_week(                        data_set=data_set,                        criterion=representative[2],                        value=representative[3])                elif representative[1] == 'average':                    selected_week = identify_average_week(                        data_set=data_set,                        criterion=representative[2])                prep_weather_data = prep_weather_data.append(selected_week)        return prep_weather_data    period_data_slices = create_period_weather_data(nodes_data['weather data'], period)    season_data = create_period_season_weather_data(period_data_slices, period, seasons=seasons)    scheme_df = pd.read_excel(scheme_path, sheet_name=str(scheme))    heuristic_periods = scheme_df.values.tolist()    prep_weather_data = select_heuristic_periods(heuristic_periods,                                                    period_data_slices,                                                    season_data,                                                    period,                                                    seasons)    for col in nodes_data['timeseries']:        prep_weather_data[col] = nodes_data['timeseries'][col]    # Rename columns of the new weather_dataset    weather_data = nodes_data['weather data']    prep_weather_data.reset_index(drop=True, inplace=True)    prep_weather_data['timestamp'] = weather_data['timestamp'][:len(prep_weather_data)]    prep_weather_data.set_index('timestamp', inplace=True)    # Replace original data with hierarchical clustered data    nodes_data['weather data'] = prep_weather_data    nodes_data['timeseries'] = prep_weather_data    nodes_data['timeseries']['timestamp'] = nodes_data['timeseries'].index    # Adapts Other Parameters (despite weatherdata) of the energy system    if period == 'weeks':        period_length = 24 * 7    elif period == 'days':        period_length = 24    k_means_parameter_adaption(nodes_data=nodes_data, clusters=len(nodes_data['weather data'])/(period_length),                               cluster_labels='nn',period=period)def random_sampling(nodes_data, period, number_of_samples):    import random as rd    weather_data=nodes_data['weather data']    data_set = nodes_data['weather data']    prep_data_set = pd.DataFrame()    cluster_vectors = extract_single_periods(data_set=weather_data,                                             column_name='temperature',                                             period=period)    print('LEN CLUSTER VECTORS')    print(len(cluster_vectors))    # generate random integers    random_integers = []    for i in range(number_of_samples):        rd.seed(i)        random = rd.randint(0,len(cluster_vectors)-1)        random_integers.append(random)    print('RANDOM INTEGER LIST')    print(random_integers)    print(max(random_integers))    column_names = [data_set.columns[i] for i in range(1, len(data_set.columns))]    prep_data_set = pd.DataFrame()    for i in range(len(column_names)):        # Extract individual weather data set for the current weather data column        data_set_column = extract_single_periods(data_set=data_set, column_name=column_names[i], period=period)        reference_data_set = []        print('LEN DATA SET COLUMN')        print(len(data_set_column))        for j in random_integers:            reference_data_set = reference_data_set + data_set_column[j]        # Appends the calculated reference days for the curent weather data collumn to the final weather data set        prep_data_set[column_names[i]] = reference_data_set    prep_weather_data = prep_data_set    # Rename columns of the new weather_dataset    prep_weather_data['timestamp'] = weather_data['timestamp'][:len(prep_weather_data)]#:int(len(prep_weather_data))]    prep_weather_data.set_index('timestamp', inplace=True)    # Replaces the weather data set in nodes_data by the new one    nodes_data['weather data'] = prep_weather_data    #    # # Adapts Other Parameters (despite weatherdata) of the energy system    if period == 'days':        adaption_clusters = len(prep_weather_data)/24    elif period == 'weeks':        adaption_clusters = len(prep_weather_data)/(24*7)    k_means_parameter_adaption(nodes_data=nodes_data,                               clusters=adaption_clusters, # TODO: relativen wert einfÃ¼gen!                               cluster_labels=0,                               period=period)    data_set = nodes_data['timeseries']    column_names = [data_set.columns[i] for i in range(1, len(data_set.columns))]    for i in range(len(column_names)):        # Extract individual weather data set for the current weather data column        data_set_column = extract_single_periods(data_set=data_set, column_name=column_names[i], period=period)        reference_data_set = []        for j in range(len(random_integers)):            reference_data_set = reference_data_set + data_set_column[random_integers[j]]        # Appends the calculated reference days for the curent weather data collumn to the final weather data set        prep_data_set[column_names[i]] = reference_data_set    prep_timeseries = prep_data_set    prep_timeseries['timestamp'] = nodes_data['timeseries']['timestamp'][:len(prep_weather_data)]    # prep_timeseries.set_index('timestamp', inplace=True)    nodes_data['timeseries'] = prep_timeseriesdef timeseries_preparation(timeseries_prep_param,                           # method,                           # days_per_cluster,                           # n_timesteps,                           nodes_data,                           scheme_path):    ''' Evaluates the passed parameters for timeseries preparation and starts    the corresponding simplification/clustering algorithm.    :param timeseries_prep_param: List of timeseries preparation parameters                                  with the scheme [algorithm, cluster_index,                                  cluster_criterion, cluster_period,                                  cluster_season]    :type timeseries_prep_param: list    :param nodes_data: Dictionary containing the energy systems data    :type nodes_data: dict    :param scheme_path: Path, where the xlsx-file with possible heuristic                        selection schemes is stored.    :type scheme_path: str    :return:    '''    data_prep = timeseries_prep_param[0]    method = timeseries_prep_param[0]    days_per_cluster = timeseries_prep_param[1]    n_timesteps = timeseries_prep_param[1]    cluster_criterion = timeseries_prep_param[2]    cluster_period = timeseries_prep_param[3]    cluster_seasons = int(timeseries_prep_param[4])    # K-MEANS ALGORITHM    if data_prep == 'k_means':        if cluster_period == 'days':            clusters = 365 // int(days_per_cluster),        elif cluster_period == 'weeks':            clusters = 52 // int(days_per_cluster)        k_means_algorithm(clusters=clusters,                          criterion=cluster_criterion,                          nodes_data=nodes_data,                          period=cluster_period)    # AVERAGING ALGORITHM    elif data_prep == 'averaging':        if cluster_period == 'days':            clusters = 365 // int(days_per_cluster),        elif cluster_period == 'weeks':            clusters = 52 // int(days_per_cluster)        timeseries_averaging(clusters=clusters,                             nodes_data=nodes_data,                             period=cluster_period)    # SLICING ALGORITHM    elif data_prep == 'slicing n>=2':        timeseries_slicing(n_days=int(days_per_cluster),                           nodes_data=nodes_data,                           period=cluster_period),    elif data_prep == 'slicing n<2':        timeseries_slicing2(n_days=int(days_per_cluster),                           nodes_data=nodes_data,                           period=cluster_period),    # DOWNSAMPLING ALGORITHM    elif data_prep == 'downsampling n>=2':        timeseries_downsampling(nodes_data, int(n_timesteps))    elif data_prep == 'downsampling n<2':        timeseries_downsampling2(nodes_data, int(n_timesteps))    # HEURISTIC SELECTION ALGORITHM    elif data_prep == 'heuristic selection':        hierarchical_selection(nodes_data=nodes_data,                               scheme=int(n_timesteps),                               period=cluster_period,                               seasons=cluster_seasons,                               scheme_path=scheme_path)    # ADAPTS THE PARAMETERS OF THE ENERGY SYSTEM    if data_prep != 'none':        path = os.path.join(            os.path.dirname(__file__) + r"\interim_data\modified_scenario.xlsx")        writer = pd.ExcelWriter(path, engine='xlsxwriter')        nodes_data['weather data'].to_excel(writer, sheet_name='weather data')        nodes_data['timeseries'].to_excel(writer, sheet_name='time_series')        nodes_data['energysystem'].to_excel(writer, sheet_name='energysystem')        writer.save()        scenario_file = path